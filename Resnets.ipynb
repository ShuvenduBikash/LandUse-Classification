{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "import copy\n",
    "from tensorboardX import SummaryWriter\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "plt.ion()   # interactive mode\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, root='D:\\\\Research\\\\data\\\\UCMerced_LandUse\\\\Images', transforms_=None, idx=[]):\n",
    "        self.transform = transforms_\n",
    "        self.files = []\n",
    "\n",
    "        for path, subdirs, files in os.walk(root):\n",
    "            for name in files:\n",
    "                self.files.append(os.path.join(path, name))\n",
    "        \n",
    "        self.files =  [self.files[i] for i in idx]\n",
    "        self.n = len(self.files)\n",
    "        \n",
    "        classes = os.listdir(root)\n",
    "        self.classes = {}\n",
    "        \n",
    "        for i, cls in enumerate(classes):\n",
    "            self.classes[cls] = i\n",
    "        print(self.classes)\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        filepath = self.files[index % len(self.files)]\n",
    "\n",
    "        cls_name = filepath.split('\\\\')[-2]\n",
    "        img = self.transform(Image.open(filepath))\n",
    "        label = self.classes[cls_name]\n",
    "\n",
    "        return img, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize(224),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(224),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "class_names = 21\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "dataset_sizes = {'val': 210, 'train': 2100-210}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def train_model(model, criterion, optimizer, scheduler, dataloaders, writer=None, i=0,  num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in tqdm(dataloaders[phase]):\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "            \n",
    "\n",
    "            writer.add_scalar(phase+\"/loss\", epoch_loss, epoch)\n",
    "            writer.add_scalar(phase+\"/acc\", epoch_acc, epoch)\n",
    "\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                # torch.save(model.state_dict(), 'saved/resnet_'+str(i)+'.pt')\n",
    "\n",
    "        print()\n",
    "        \n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, best_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resnet 152"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'agricultural': 0, 'airplane': 1, 'baseballdiamond': 2, 'beach': 3, 'buildings': 4, 'chaparral': 5, 'denseresidential': 6, 'forest': 7, 'freeway': 8, 'golfcourse': 9, 'harbor': 10, 'intersection': 11, 'mediumresidential': 12, 'mobilehomepark': 13, 'overpass': 14, 'parkinglot': 15, 'river': 16, 'runway': 17, 'sparseresidential': 18, 'storagetanks': 19, 'tenniscourt': 20}\n",
      "{'agricultural': 0, 'airplane': 1, 'baseballdiamond': 2, 'beach': 3, 'buildings': 4, 'chaparral': 5, 'denseresidential': 6, 'forest': 7, 'freeway': 8, 'golfcourse': 9, 'harbor': 10, 'intersection': 11, 'mediumresidential': 12, 'mobilehomepark': 13, 'overpass': 14, 'parkinglot': 15, 'river': 16, 'runway': 17, 'sparseresidential': 18, 'storagetanks': 19, 'tenniscourt': 20}\n",
      "Epoch 0/19\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 473/473 [02:05<00:00,  3.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 1.6459 Acc: 0.5492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 53/53 [00:04<00:00, 12.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.7126 Acc: 0.8952\n",
      "\n",
      "Epoch 1/19\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 473/473 [02:03<00:00,  3.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.5256 Acc: 0.8720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 53/53 [00:04<00:00, 12.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.4560 Acc: 0.9429\n",
      "\n",
      "Epoch 2/19\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 473/473 [02:04<00:00,  3.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.3283 Acc: 0.9159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 53/53 [00:04<00:00, 13.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.3540 Acc: 0.9476\n",
      "\n",
      "Epoch 3/19\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 473/473 [02:03<00:00,  3.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2035 Acc: 0.9497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 53/53 [00:04<00:00, 12.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.5555 Acc: 0.9429\n",
      "\n",
      "Epoch 4/19\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 473/473 [02:03<00:00,  3.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1643 Acc: 0.9582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 53/53 [00:04<00:00, 12.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.7205 Acc: 0.9381\n",
      "\n",
      "Epoch 5/19\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 473/473 [02:02<00:00,  3.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1438 Acc: 0.9587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 53/53 [00:04<00:00, 13.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.2855 Acc: 0.9667\n",
      "\n",
      "Epoch 6/19\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 473/473 [02:01<00:00,  3.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1047 Acc: 0.9757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 53/53 [00:04<00:00, 13.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.4569 Acc: 0.9524\n",
      "\n",
      "Epoch 7/19\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 473/473 [02:01<00:00,  3.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1048 Acc: 0.9746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 53/53 [00:04<00:00, 13.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.2773 Acc: 0.9667\n",
      "\n",
      "Epoch 8/19\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 473/473 [02:01<00:00,  3.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0920 Acc: 0.9783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 53/53 [00:03<00:00, 13.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.4814 Acc: 0.9524\n",
      "\n",
      "Epoch 9/19\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 473/473 [02:01<00:00,  3.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0936 Acc: 0.9794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 53/53 [00:04<00:00, 13.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.3245 Acc: 0.9619\n",
      "\n",
      "Epoch 10/19\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 473/473 [02:01<00:00,  3.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0761 Acc: 0.9825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 53/53 [00:04<00:00, 12.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.3274 Acc: 0.9714\n",
      "\n",
      "Epoch 11/19\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 473/473 [02:01<00:00,  3.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0845 Acc: 0.9815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 53/53 [00:03<00:00, 13.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.3066 Acc: 0.9714\n",
      "\n",
      "Epoch 12/19\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 473/473 [02:04<00:00,  3.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0946 Acc: 0.9788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 53/53 [00:04<00:00, 12.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.2100 Acc: 0.9762\n",
      "\n",
      "Epoch 13/19\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 473/473 [02:07<00:00,  3.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0805 Acc: 0.9831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 53/53 [00:04<00:00, 12.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.2597 Acc: 0.9762\n",
      "\n",
      "Epoch 14/19\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 473/473 [02:08<00:00,  3.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0685 Acc: 0.9878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 53/53 [00:04<00:00, 12.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.3307 Acc: 0.9667\n",
      "\n",
      "Epoch 15/19\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 473/473 [02:04<00:00,  3.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0756 Acc: 0.9868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 53/53 [00:04<00:00, 12.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.2238 Acc: 0.9762\n",
      "\n",
      "Epoch 16/19\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 473/473 [02:08<00:00,  3.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0785 Acc: 0.9831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 53/53 [00:04<00:00, 11.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.3849 Acc: 0.9667\n",
      "\n",
      "Epoch 17/19\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 473/473 [02:21<00:00,  3.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0819 Acc: 0.9810\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 53/53 [00:05<00:00, 10.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.3221 Acc: 0.9714\n",
      "\n",
      "Epoch 18/19\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 473/473 [02:24<00:00,  3.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0731 Acc: 0.9862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 53/53 [00:05<00:00,  9.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.1586 Acc: 0.9762\n",
      "\n",
      "Epoch 19/19\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 473/473 [02:22<00:00,  3.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0912 Acc: 0.9799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 53/53 [00:04<00:00, 10.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.8307 Acc: 0.9429\n",
      "\n",
      "Training complete in 43m 40s\n",
      "Best val Acc: 0.976190\n",
      "\n",
      "\n",
      "\n",
      "------------------------------------\n",
      " Accuracies  [0.9761904761904763]\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracies = []\n",
    "np.random.seed(0)\n",
    "index = list(np.random.permutation(2100))\n",
    "\n",
    "\n",
    "for i in range(1):\n",
    "    idx = {'val': index[210*i:210*(i+1)], 'train': index[:i*210]+index[((i+1)*210) -1:]}\n",
    "\n",
    "    dataloaders = {x: torch.utils.data.DataLoader(CustomDataset(transforms_=data_transforms[x], idx=idx[x]), batch_size=4,\n",
    "                                             shuffle=True)\n",
    "              for x in ['train', 'val']}\n",
    "\n",
    "    \n",
    "    model_ft = models.resnet152(pretrained=True)\n",
    "    num_ftrs = model_ft.fc.in_features\n",
    "    model_ft.fc = nn.Linear(num_ftrs, class_names)\n",
    "    \n",
    "    model_ft = model_ft.to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.0005, momentum=0.9)\n",
    "    exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=6, gamma=0.1)\n",
    "    writer = SummaryWriter('./logs/densenet161_kfold_'+str(i))\n",
    "\n",
    "    model_ft, best_acc = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                                     dataloaders, writer, i, num_epochs=20)\n",
    "    \n",
    "    accuracies.append(best_acc.item())\n",
    "    print(\"\\n\\n\\n------------------------------------\\n Accuracies \", accuracies)\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_ft.state_dict(), 'saved/resnet_152.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'agricultural': 0, 'airplane': 1, 'baseballdiamond': 2, 'beach': 3, 'buildings': 4, 'chaparral': 5, 'denseresidential': 6, 'forest': 7, 'freeway': 8, 'golfcourse': 9, 'harbor': 10, 'intersection': 11, 'mediumresidential': 12, 'mobilehomepark': 13, 'overpass': 14, 'parkinglot': 15, 'river': 16, 'runway': 17, 'sparseresidential': 18, 'storagetanks': 19, 'tenniscourt': 20}\n",
      "{'agricultural': 0, 'airplane': 1, 'baseballdiamond': 2, 'beach': 3, 'buildings': 4, 'chaparral': 5, 'denseresidential': 6, 'forest': 7, 'freeway': 8, 'golfcourse': 9, 'harbor': 10, 'intersection': 11, 'mediumresidential': 12, 'mobilehomepark': 13, 'overpass': 14, 'parkinglot': 15, 'river': 16, 'runway': 17, 'sparseresidential': 18, 'storagetanks': 19, 'tenniscourt': 20}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 210/210 [00:14<00:00, 14.09it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[10, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 14, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 10, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 11, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 11, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 10, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 14, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 11, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 5, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 17, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 8, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0],\n",
       " [0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 12, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 12]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = model_ft\n",
    "model.eval()\n",
    "result = [[0 for _ in range(21)] for _ in range(21)]\n",
    "\n",
    "dataloaders = {x: torch.utils.data.DataLoader(CustomDataset(transforms_=data_transforms[x], idx=idx[x]), batch_size=1,\n",
    "                                             shuffle=True)\n",
    "              for x in ['train', 'val']}\n",
    "\n",
    "for inputs, labels in tqdm(dataloaders['val']):\n",
    "    inputs = inputs.to(device)\n",
    "    labels = labels.to(device)\n",
    "\n",
    "\n",
    "    outputs = model_ft(inputs)\n",
    "    _, preds = torch.max(outputs, 1)\n",
    "    \n",
    "    row = preds.data[0].cpu().numpy()\n",
    "    col = labels.data[0].cpu().numpy() \n",
    "    result[row][col]+=1\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Row Sum: \n",
      " [10  9 14 10 13 11  4 11  9  6 10 14  4 11  6 17  7  8  9 15 12]\n",
      "\n",
      "Col Sum: \n",
      " [10  9 14 13 13 11  5 11  9  6 10 15  3 11  5 17  7  8  9 12 12]\n",
      "\n",
      "Precision\n",
      " [1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 0.75       1.         0.83333333 1.         1.         1.\n",
      " 1.         0.8        1.        ]\n",
      "\n",
      "Recall\n",
      " [1.         1.         1.         0.76923077 1.         1.\n",
      " 0.8        1.         1.         1.         1.         0.93333333\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.        ]\n",
      "\n",
      "Model average prcision:  0.9706349206349207\n",
      "Model average recall:  0.9763125763125762\n",
      "Model accuracy:  0.9761904761904762\n"
     ]
    }
   ],
   "source": [
    "precision = np.zeros(21)\n",
    "recall = np.zeros(21)\n",
    "\n",
    "npr = np.array(result)\n",
    "row_sum = npr.sum(axis=1)\n",
    "print(\"\\nRow Sum: \\n\", row_sum)\n",
    "col_sum = npr.sum(axis=0)\n",
    "print(\"\\nCol Sum: \\n\", col_sum)\n",
    "total_correct = 0\n",
    "\n",
    "for i in range(21):\n",
    "    precision[i] = result[i][i] / row_sum[i]\n",
    "    recall[i] = result[i][i] / col_sum[i]\n",
    "    total_correct += result[i][i]\n",
    "\n",
    "print(\"\\nPrecision\\n\", precision)\n",
    "print(\"\\nRecall\\n\", recall)\n",
    "\n",
    "\n",
    "print()\n",
    "print(\"Model average prcision: \", np.mean(precision))\n",
    "print(\"Model average recall: \", np.mean(recall))\n",
    "print(\"Model accuracy: \", total_correct/210)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resnet 101\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'agricultural': 0, 'airplane': 1, 'baseballdiamond': 2, 'beach': 3, 'buildings': 4, 'chaparral': 5, 'denseresidential': 6, 'forest': 7, 'freeway': 8, 'golfcourse': 9, 'harbor': 10, 'intersection': 11, 'mediumresidential': 12, 'mobilehomepark': 13, 'overpass': 14, 'parkinglot': 15, 'river': 16, 'runway': 17, 'sparseresidential': 18, 'storagetanks': 19, 'tenniscourt': 20}\n",
      "{'agricultural': 0, 'airplane': 1, 'baseballdiamond': 2, 'beach': 3, 'buildings': 4, 'chaparral': 5, 'denseresidential': 6, 'forest': 7, 'freeway': 8, 'golfcourse': 9, 'harbor': 10, 'intersection': 11, 'mediumresidential': 12, 'mobilehomepark': 13, 'overpass': 14, 'parkinglot': 15, 'river': 16, 'runway': 17, 'sparseresidential': 18, 'storagetanks': 19, 'tenniscourt': 20}\n",
      "Epoch 0/19\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 237/237 [01:13<00:00,  3.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 1.6902 Acc: 0.5836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 27/27 [00:02<00:00, 10.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.4060 Acc: 0.9048\n",
      "\n",
      "Epoch 1/19\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 237/237 [01:13<00:00,  3.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.4831 Acc: 0.8931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 27/27 [00:03<00:00,  8.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.3260 Acc: 0.9238\n",
      "\n",
      "Epoch 2/19\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 237/237 [01:12<00:00,  3.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2487 Acc: 0.9471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 27/27 [00:02<00:00, 10.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.2901 Acc: 0.9429\n",
      "\n",
      "Epoch 3/19\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 237/237 [01:10<00:00,  3.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1580 Acc: 0.9651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 27/27 [00:02<00:00,  9.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.4112 Acc: 0.9381\n",
      "\n",
      "Epoch 4/19\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 237/237 [01:11<00:00,  3.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1311 Acc: 0.9730\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 27/27 [00:02<00:00,  9.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.3054 Acc: 0.9476\n",
      "\n",
      "Epoch 5/19\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 237/237 [01:09<00:00,  3.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1145 Acc: 0.9757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 27/27 [00:02<00:00, 10.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.1900 Acc: 0.9524\n",
      "\n",
      "Epoch 6/19\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 237/237 [01:08<00:00,  3.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0719 Acc: 0.9889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 27/27 [00:02<00:00, 10.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.1466 Acc: 0.9619\n",
      "\n",
      "Epoch 7/19\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 237/237 [01:10<00:00,  3.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0848 Acc: 0.9841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 27/27 [00:02<00:00,  9.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.2456 Acc: 0.9429\n",
      "\n",
      "Epoch 8/19\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 237/237 [01:09<00:00,  3.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0640 Acc: 0.9915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 27/27 [00:02<00:00,  9.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.3580 Acc: 0.9381\n",
      "\n",
      "Epoch 9/19\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 237/237 [01:13<00:00,  3.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0659 Acc: 0.9894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 27/27 [00:02<00:00,  9.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.1320 Acc: 0.9524\n",
      "\n",
      "Epoch 10/19\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████████████████████████████████████████████████████████████▍                | 188/237 [00:58<00:15,  3.23it/s]"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "index = list(np.random.permutation(2100))\n",
    "\n",
    "for i in range(1):\n",
    "    idx = {'val': index[210*i:210*(i+1)], 'train': index[:i*210]+index[((i+1)*210) -1:]}\n",
    "\n",
    "    dataloaders = {x: torch.utils.data.DataLoader(CustomDataset(transforms_=data_transforms[x], idx=idx[x]), batch_size=8,\n",
    "                                             shuffle=True)\n",
    "              for x in ['train', 'val']}\n",
    "\n",
    "    \n",
    "    model_ft = models.resnet101(pretrained=True)\n",
    "    num_ftrs = model_ft.fc.in_features\n",
    "    model_ft.fc = nn.Linear(num_ftrs, class_names)\n",
    "    \n",
    "    model_ft = model_ft.to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.0005, momentum=0.9)\n",
    "    exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=6, gamma=0.1)\n",
    "    writer = SummaryWriter('./logs/densenet161_kfold_'+str(i))\n",
    "\n",
    "    model_ft, best_acc = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                                     dataloaders, writer, i, num_epochs=20)\n",
    "    \n",
    "    accuracies.append(best_acc.item())\n",
    "    print(\"\\n\\n\\n------------------------------------\\n Accuracies \", accuracies)\n",
    "    print(\"\\n\\n\")\n",
    "    \n",
    "torch.save(model_ft.state_dict(), 'saved/resnet_101.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_ft\n",
    "model.eval()\n",
    "result = [[0 for _ in range(21)] for _ in range(21)]\n",
    "\n",
    "dataloaders = {x: torch.utils.data.DataLoader(CustomDataset(transforms_=data_transforms[x], idx=idx[x]), batch_size=1,\n",
    "                                             shuffle=True)\n",
    "              for x in ['train', 'val']}\n",
    "\n",
    "for inputs, labels in tqdm(dataloaders['val']):\n",
    "    inputs = inputs.to(device)\n",
    "    labels = labels.to(device)\n",
    "\n",
    "\n",
    "    outputs = model_ft(inputs)\n",
    "    _, preds = torch.max(outputs, 1)\n",
    "    \n",
    "    row = preds.data[0].cpu().numpy()\n",
    "    col = labels.data[0].cpu().numpy() \n",
    "    result[row][col]+=1\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = np.zeros(21)\n",
    "recall = np.zeros(21)\n",
    "\n",
    "npr = np.array(result)\n",
    "row_sum = npr.sum(axis=1)\n",
    "print(\"\\nRow Sum: \\n\", row_sum)\n",
    "col_sum = npr.sum(axis=0)\n",
    "print(\"\\nCol Sum: \\n\", col_sum)\n",
    "total_correct = 0\n",
    "\n",
    "for i in range(21):\n",
    "    precision[i] = result[i][i] / row_sum[i]\n",
    "    recall[i] = result[i][i] / col_sum[i]\n",
    "    total_correct += result[i][i]\n",
    "\n",
    "print(\"\\nPrecision\\n\", precision)\n",
    "print(\"\\nRecall\\n\", recall)\n",
    "\n",
    "\n",
    "print()\n",
    "print(\"Model average prcision: \", np.mean(precision))\n",
    "print(\"Model average recall: \", np.mean(recall))\n",
    "print(\"Model accuracy: \", total_correct/210)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resnet 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "index = list(np.random.permutation(2100))\n",
    "\n",
    "for i in range(1):\n",
    "    idx = {'val': index[210*i:210*(i+1)], 'train': index[:i*210]+index[((i+1)*210) -1:]}\n",
    "\n",
    "    dataloaders = {x: torch.utils.data.DataLoader(CustomDataset(transforms_=data_transforms[x], idx=idx[x]), batch_size=8,\n",
    "                                             shuffle=True)\n",
    "              for x in ['train', 'val']}\n",
    "\n",
    "    \n",
    "    model_ft = models.resnet50(pretrained=True)\n",
    "    num_ftrs = model_ft.fc.in_features\n",
    "    model_ft.fc = nn.Linear(num_ftrs, class_names)\n",
    "    \n",
    "    model_ft = model_ft.to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.0005, momentum=0.9)\n",
    "    exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=6, gamma=0.1)\n",
    "    writer = SummaryWriter('./logs/densenet161_kfold_'+str(i))\n",
    "\n",
    "    model_ft, best_acc = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                                     dataloaders, writer, i, num_epochs=20)\n",
    "    \n",
    "    accuracies.append(best_acc.item())\n",
    "    print(\"\\n\\n\\n------------------------------------\\n Accuracies \", accuracies)\n",
    "    print(\"\\n\\n\")\n",
    "    \n",
    "torch.save(model_ft.state_dict(), 'saved/resnet_50.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_ft\n",
    "model.eval()\n",
    "result = [[0 for _ in range(21)] for _ in range(21)]\n",
    "\n",
    "dataloaders = {x: torch.utils.data.DataLoader(CustomDataset(transforms_=data_transforms[x], idx=idx[x]), batch_size=1,\n",
    "                                             shuffle=True)\n",
    "              for x in ['train', 'val']}\n",
    "\n",
    "for inputs, labels in tqdm(dataloaders['val']):\n",
    "    inputs = inputs.to(device)\n",
    "    labels = labels.to(device)\n",
    "\n",
    "\n",
    "    outputs = model_ft(inputs)\n",
    "    _, preds = torch.max(outputs, 1)\n",
    "    \n",
    "    row = preds.data[0].cpu().numpy()\n",
    "    col = labels.data[0].cpu().numpy() \n",
    "    result[row][col]+=1\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = np.zeros(21)\n",
    "recall = np.zeros(21)\n",
    "\n",
    "npr = np.array(result)\n",
    "row_sum = npr.sum(axis=1)\n",
    "print(\"\\nRow Sum: \\n\", row_sum)\n",
    "col_sum = npr.sum(axis=0)\n",
    "print(\"\\nCol Sum: \\n\", col_sum)\n",
    "total_correct = 0\n",
    "\n",
    "for i in range(21):\n",
    "    precision[i] = result[i][i] / row_sum[i]\n",
    "    recall[i] = result[i][i] / col_sum[i]\n",
    "    total_correct += result[i][i]\n",
    "\n",
    "print(\"\\nPrecision\\n\", precision)\n",
    "print(\"\\nRecall\\n\", recall)\n",
    "\n",
    "\n",
    "print()\n",
    "print(\"Model average prcision: \", np.mean(precision))\n",
    "print(\"Model average recall: \", np.mean(recall))\n",
    "print(\"Model accuracy: \", total_correct/210)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resnet 34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "index = list(np.random.permutation(2100))\n",
    "\n",
    "for i in range(1):\n",
    "    idx = {'val': index[210*i:210*(i+1)], 'train': index[:i*210]+index[((i+1)*210) -1:]}\n",
    "\n",
    "    dataloaders = {x: torch.utils.data.DataLoader(CustomDataset(transforms_=data_transforms[x], idx=idx[x]), batch_size=8,\n",
    "                                             shuffle=True)\n",
    "              for x in ['train', 'val']}\n",
    "\n",
    "    \n",
    "    model_ft = models.resnet34(pretrained=True)\n",
    "    num_ftrs = model_ft.fc.in_features\n",
    "    model_ft.fc = nn.Linear(num_ftrs, class_names)\n",
    "    \n",
    "    model_ft = model_ft.to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.0005, momentum=0.9)\n",
    "    exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=6, gamma=0.1)\n",
    "    writer = SummaryWriter('./logs/densenet161_kfold_'+str(i))\n",
    "\n",
    "    model_ft, best_acc = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                                     dataloaders, writer, i, num_epochs=20)\n",
    "    \n",
    "    accuracies.append(best_acc.item())\n",
    "    print(\"\\n\\n\\n------------------------------------\\n Accuracies \", accuracies)\n",
    "    print(\"\\n\\n\")\n",
    "    \n",
    "torch.save(model_ft.state_dict(), 'saved/resnet_34.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_ft\n",
    "model.eval()\n",
    "result = [[0 for _ in range(21)] for _ in range(21)]\n",
    "\n",
    "dataloaders = {x: torch.utils.data.DataLoader(CustomDataset(transforms_=data_transforms[x], idx=idx[x]), batch_size=1,\n",
    "                                             shuffle=True)\n",
    "              for x in ['train', 'val']}\n",
    "\n",
    "for inputs, labels in tqdm(dataloaders['val']):\n",
    "    inputs = inputs.to(device)\n",
    "    labels = labels.to(device)\n",
    "\n",
    "\n",
    "    outputs = model_ft(inputs)\n",
    "    _, preds = torch.max(outputs, 1)\n",
    "    \n",
    "    row = preds.data[0].cpu().numpy()\n",
    "    col = labels.data[0].cpu().numpy() \n",
    "    result[row][col]+=1\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = np.zeros(21)\n",
    "recall = np.zeros(21)\n",
    "\n",
    "npr = np.array(result)\n",
    "row_sum = npr.sum(axis=1)\n",
    "print(\"\\nRow Sum: \\n\", row_sum)\n",
    "col_sum = npr.sum(axis=0)\n",
    "print(\"\\nCol Sum: \\n\", col_sum)\n",
    "total_correct = 0\n",
    "\n",
    "for i in range(21):\n",
    "    precision[i] = result[i][i] / row_sum[i]\n",
    "    recall[i] = result[i][i] / col_sum[i]\n",
    "    total_correct += result[i][i]\n",
    "\n",
    "print(\"\\nPrecision\\n\", precision)\n",
    "print(\"\\nRecall\\n\", recall)\n",
    "\n",
    "\n",
    "print()\n",
    "print(\"Model average prcision: \", np.mean(precision))\n",
    "print(\"Model average recall: \", np.mean(recall))\n",
    "print(\"Model accuracy: \", total_correct/210)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resnet 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "index = list(np.random.permutation(2100))\n",
    "\n",
    "for i in range(1):\n",
    "    idx = {'val': index[210*i:210*(i+1)], 'train': index[:i*210]+index[((i+1)*210) -1:]}\n",
    "\n",
    "    dataloaders = {x: torch.utils.data.DataLoader(CustomDataset(transforms_=data_transforms[x], idx=idx[x]), batch_size=8,\n",
    "                                             shuffle=True)\n",
    "              for x in ['train', 'val']}\n",
    "\n",
    "    \n",
    "    model_ft = models.resnet18(pretrained=True)\n",
    "    num_ftrs = model_ft.fc.in_features\n",
    "    model_ft.fc = nn.Linear(num_ftrs, class_names)\n",
    "    \n",
    "    model_ft = model_ft.to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.0005, momentum=0.9)\n",
    "    exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=6, gamma=0.1)\n",
    "    writer = SummaryWriter('./logs/densenet161_kfold_'+str(i))\n",
    "\n",
    "    model_ft, best_acc = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                                     dataloaders, writer, i, num_epochs=20)\n",
    "    \n",
    "    accuracies.append(best_acc.item())\n",
    "    print(\"\\n\\n\\n------------------------------------\\n Accuracies \", accuracies)\n",
    "    print(\"\\n\\n\")\n",
    "    \n",
    "torch.save(model_ft.state_dict(), 'saved/resnet_18.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_ft\n",
    "model.eval()\n",
    "result = [[0 for _ in range(21)] for _ in range(21)]\n",
    "\n",
    "dataloaders = {x: torch.utils.data.DataLoader(CustomDataset(transforms_=data_transforms[x], idx=idx[x]), batch_size=1,\n",
    "                                             shuffle=True)\n",
    "              for x in ['train', 'val']}\n",
    "\n",
    "for inputs, labels in tqdm(dataloaders['val']):\n",
    "    inputs = inputs.to(device)\n",
    "    labels = labels.to(device)\n",
    "\n",
    "\n",
    "    outputs = model_ft(inputs)\n",
    "    _, preds = torch.max(outputs, 1)\n",
    "    \n",
    "    row = preds.data[0].cpu().numpy()\n",
    "    col = labels.data[0].cpu().numpy() \n",
    "    result[row][col]+=1\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = np.zeros(21)\n",
    "recall = np.zeros(21)\n",
    "\n",
    "npr = np.array(result)\n",
    "row_sum = npr.sum(axis=1)\n",
    "print(\"\\nRow Sum: \\n\", row_sum)\n",
    "col_sum = npr.sum(axis=0)\n",
    "print(\"\\nCol Sum: \\n\", col_sum)\n",
    "total_correct = 0\n",
    "\n",
    "for i in range(21):\n",
    "    precision[i] = result[i][i] / row_sum[i]\n",
    "    recall[i] = result[i][i] / col_sum[i]\n",
    "    total_correct += result[i][i]\n",
    "\n",
    "print(\"\\nPrecision\\n\", precision)\n",
    "print(\"\\nRecall\\n\", recall)\n",
    "\n",
    "\n",
    "print()\n",
    "print(\"Model average prcision: \", np.mean(precision))\n",
    "print(\"Model average recall: \", np.mean(recall))\n",
    "print(\"Model accuracy: \", total_correct/210)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
