{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "import copy\n",
    "from tensorboardX import SummaryWriter\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "plt.ion()   # interactive mode\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, root='D:\\\\Research\\\\data\\\\UCMerced_LandUse\\\\Images', transforms_=None, idx=[]):\n",
    "        self.transform = transforms_\n",
    "        self.files = []\n",
    "\n",
    "        for path, subdirs, files in os.walk(root):\n",
    "            for name in files:\n",
    "                self.files.append(os.path.join(path, name))\n",
    "        \n",
    "        self.files =  [self.files[i] for i in idx]\n",
    "        self.n = len(self.files)\n",
    "        \n",
    "        classes = os.listdir(root)\n",
    "        self.classes = {}\n",
    "        \n",
    "        for i, cls in enumerate(classes):\n",
    "            self.classes[cls] = i\n",
    "        print(self.classes)\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        filepath = self.files[index % len(self.files)]\n",
    "\n",
    "        cls_name = filepath.split('\\\\')[-2]\n",
    "        img = self.transform(Image.open(filepath))\n",
    "        label = self.classes[cls_name]\n",
    "\n",
    "        return img, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize(224),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(224),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "class_names = 21\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "dataset_sizes = {'val': 210, 'train': 2100-210}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def train_model(model, criterion, optimizer, scheduler, dataloaders, writer=None, i=0,  num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in tqdm(dataloaders[phase]):\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "            \n",
    "\n",
    "            writer.add_scalar(phase+\"/loss\", epoch_loss, epoch)\n",
    "            writer.add_scalar(phase+\"/acc\", epoch_acc, epoch)\n",
    "\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                # torch.save(model.state_dict(), 'saved/resnet_'+str(i)+'.pt')\n",
    "\n",
    "        print()\n",
    "        \n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, best_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resnet 152"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/19\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 119/119 [02:51<00:00,  1.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 2.0814 Acc: 0.5365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:10<00:00,  1.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.9571 Acc: 0.8619\n",
      "\n",
      "Epoch 1/19\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 119/119 [01:17<00:00,  1.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.7210 Acc: 0.8778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:02<00:00,  5.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.3308 Acc: 0.9524\n",
      "\n",
      "Epoch 2/19\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 119/119 [01:16<00:00,  1.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.3421 Acc: 0.9354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:02<00:00,  4.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.1522 Acc: 0.9810\n",
      "\n",
      "Epoch 3/19\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 119/119 [01:15<00:00,  1.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2003 Acc: 0.9683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:02<00:00,  4.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.1024 Acc: 0.9810\n",
      "\n",
      "Epoch 4/19\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 119/119 [01:16<00:00,  1.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1344 Acc: 0.9778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:02<00:00,  4.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.0677 Acc: 0.9810\n",
      "\n",
      "Epoch 5/19\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 119/119 [01:17<00:00,  1.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1030 Acc: 0.9847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:03<00:00,  4.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.0548 Acc: 0.9857\n",
      "\n",
      "Epoch 6/19\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 119/119 [01:17<00:00,  1.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0846 Acc: 0.9894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:02<00:00,  5.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.0575 Acc: 0.9857\n",
      "\n",
      "Epoch 7/19\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 119/119 [01:17<00:00,  1.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0734 Acc: 0.9894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:02<00:00,  4.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.0487 Acc: 0.9905\n",
      "\n",
      "Epoch 8/19\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 119/119 [01:16<00:00,  1.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0781 Acc: 0.9915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:02<00:00,  4.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.0673 Acc: 0.9810\n",
      "\n",
      "Epoch 9/19\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 119/119 [01:16<00:00,  1.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0757 Acc: 0.9905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:02<00:00,  4.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.0552 Acc: 0.9857\n",
      "\n",
      "Epoch 10/19\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 119/119 [01:17<00:00,  1.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0682 Acc: 0.9942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:02<00:00,  4.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.0514 Acc: 0.9857\n",
      "\n",
      "Epoch 11/19\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 119/119 [01:16<00:00,  1.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0659 Acc: 0.9937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:02<00:00,  4.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.0508 Acc: 0.9905\n",
      "\n",
      "Epoch 12/19\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 119/119 [01:17<00:00,  1.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0722 Acc: 0.9878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:02<00:00,  5.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.0550 Acc: 0.9810\n",
      "\n",
      "Epoch 13/19\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 119/119 [01:16<00:00,  1.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0761 Acc: 0.9915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:02<00:00,  5.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.0460 Acc: 0.9857\n",
      "\n",
      "Epoch 14/19\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 119/119 [01:17<00:00,  1.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0670 Acc: 0.9947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:02<00:00,  5.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.0565 Acc: 0.9905\n",
      "\n",
      "Epoch 15/19\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 119/119 [01:17<00:00,  1.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0700 Acc: 0.9926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:02<00:00,  4.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.0499 Acc: 0.9857\n",
      "\n",
      "Epoch 16/19\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 119/119 [01:17<00:00,  1.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0713 Acc: 0.9937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:02<00:00,  4.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.0531 Acc: 0.9905\n",
      "\n",
      "Epoch 17/19\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 119/119 [01:17<00:00,  1.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0668 Acc: 0.9947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:02<00:00,  4.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.0453 Acc: 0.9905\n",
      "\n",
      "Epoch 18/19\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 119/119 [01:17<00:00,  1.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0752 Acc: 0.9905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:02<00:00,  4.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.0582 Acc: 0.9905\n",
      "\n",
      "Epoch 19/19\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|██▊                                                                               | 4/119 [00:02<01:19,  1.45it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-4a1b52ade63c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m     model_ft, best_acc = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n\u001b[1;32m---> 26\u001b[1;33m                                      dataloaders, writer, i, num_epochs=20)\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[0maccuracies\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbest_acc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-5aead8b591f6>\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(model, criterion, optimizer, scheduler, dataloaders, writer, i, num_epochs)\u001b[0m\n\u001b[0;32m     40\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mphase\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'train'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m                         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m                         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m                 \u001b[1;31m# statistics\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\optim\\sgd.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m     99\u001b[0m                     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m                         \u001b[0mbuf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparam_state\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'momentum_buffer'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 101\u001b[1;33m                         \u001b[0mbuf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmomentum\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mdampening\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md_p\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    102\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mnesterov\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m                         \u001b[0md_p\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0md_p\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmomentum\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "accuracies = []\n",
    "np.random.seed(0)\n",
    "index = list(np.random.permutation(2100))\n",
    "\n",
    "\n",
    "for i in range(1):\n",
    "    idx = {'val': index[210*i:210*(i+1)], 'train': index[:i*210]+index[((i+1)*210) -1:]}\n",
    "\n",
    "    dataloaders = {x: torch.utils.data.DataLoader(CustomDataset(transforms_=data_transforms[x], idx=idx[x]), batch_size=4,\n",
    "                                             shuffle=True)\n",
    "              for x in ['train', 'val']}\n",
    "\n",
    "    \n",
    "    model_ft = models.resnet152(pretrained=True)\n",
    "    num_ftrs = model_ft.fc.in_features\n",
    "    model_ft.fc = nn.Linear(num_ftrs, class_names)\n",
    "    \n",
    "    model_ft = model_ft.to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.0005, momentum=0.9)\n",
    "    exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=6, gamma=0.1)\n",
    "    writer = SummaryWriter('./logs/densenet161_kfold_'+str(i))\n",
    "\n",
    "    model_ft, best_acc = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                                     dataloaders, writer, i, num_epochs=20)\n",
    "    \n",
    "    accuracies.append(best_acc.item())\n",
    "    print(\"\\n\\n\\n------------------------------------\\n Accuracies \", accuracies)\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_ft.state_dict(), 'saved/resnet_152.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_ft\n",
    "model.eval()\n",
    "result = [[0 for _ in range(21)] for _ in range(21)]\n",
    "\n",
    "dataloaders = {x: torch.utils.data.DataLoader(CustomDataset(transforms_=data_transforms[x], idx=idx[x]), batch_size=1,\n",
    "                                             shuffle=True)\n",
    "              for x in ['train', 'val']}\n",
    "\n",
    "for inputs, labels in tqdm(dataloaders['val']):\n",
    "    inputs = inputs.to(device)\n",
    "    labels = labels.to(device)\n",
    "\n",
    "\n",
    "    outputs = model_ft(inputs)\n",
    "    _, preds = torch.max(outputs, 1)\n",
    "    \n",
    "    row = preds.data[0].cpu().numpy()\n",
    "    col = labels.data[0].cpu().numpy() \n",
    "    result[row][col]+=1\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = np.zeros(21)\n",
    "recall = np.zeros(21)\n",
    "\n",
    "npr = np.array(result)\n",
    "row_sum = npr.sum(axis=1)\n",
    "print(\"\\nRow Sum: \\n\", row_sum)\n",
    "col_sum = npr.sum(axis=0)\n",
    "print(\"\\nCol Sum: \\n\", col_sum)\n",
    "total_correct = 0\n",
    "\n",
    "for i in range(21):\n",
    "    precision[i] = result[i][i] / row_sum[i]\n",
    "    recall[i] = result[i][i] / col_sum[i]\n",
    "    total_correct += result[i][i]\n",
    "\n",
    "print(\"\\nPrecision\\n\", precision)\n",
    "print(\"\\nRecall\\n\", recall)\n",
    "\n",
    "\n",
    "print()\n",
    "print(\"Model average prcision: \", np.mean(precision))\n",
    "print(\"Model average recall: \", np.mean(recall))\n",
    "print(\"Model accuracy: \", total_correct/210)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resnet 101\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/19\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 237/237 [01:06<00:00,  3.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 1.7444 Acc: 0.5519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 27/27 [00:02<00:00, 10.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.6774 Acc: 0.8952\n",
      "\n",
      "Epoch 1/19\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▋                                                                                 | 2/237 [00:00<01:05,  3.60it/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-2fdf5220f0ac>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     model_ft, best_acc = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n\u001b[1;32m---> 25\u001b[1;33m                                      dataloaders, writer, i, num_epochs=20)\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[0maccuracies\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbest_acc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-5aead8b591f6>\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(model, criterion, optimizer, scheduler, dataloaders, writer, i, num_epochs)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m             \u001b[1;31m# Iterate over data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataloaders\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mphase\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m                 \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m                 \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tqdm\\_tqdm.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    931\u001b[0m \"\"\", fp_write=getattr(self.fp, 'write', sys.stderr.write))\n\u001b[0;32m    932\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 933\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    934\u001b[0m                 \u001b[1;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    935\u001b[0m                 \u001b[1;31m# Update and possibly print the progressbar.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    613\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# same-process loading\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    614\u001b[0m             \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 615\u001b[1;33m             \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    616\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    617\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    613\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# same-process loading\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    614\u001b[0m             \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 615\u001b[1;33m             \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    616\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    617\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-71a0a2db5c93>\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[0mcls_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\\\'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m         \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m         \u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcls_name\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torchvision\\transforms\\transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m             \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torchvision\\transforms\\transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, tensor)\u001b[0m\n\u001b[0;32m    153\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mNormalized\u001b[0m \u001b[0mTensor\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m         \"\"\"\n\u001b[1;32m--> 155\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    156\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    157\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torchvision\\transforms\\functional.py\u001b[0m in \u001b[0;36mnormalize\u001b[1;34m(tensor, mean, std)\u001b[0m\n\u001b[0;32m    178\u001b[0m     \u001b[1;31m# This is faster than using broadcasting, don't change without benchmarking\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 180\u001b[1;33m         \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msub_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdiv_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    181\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "index = list(np.random.permutation(2100))\n",
    "\n",
    "for i in range(1):\n",
    "    idx = {'val': index[210*i:210*(i+1)], 'train': index[:i*210]+index[((i+1)*210) -1:]}\n",
    "\n",
    "    dataloaders = {x: torch.utils.data.DataLoader(CustomDataset(transforms_=data_transforms[x], idx=idx[x]), batch_size=8,\n",
    "                                             shuffle=True)\n",
    "              for x in ['train', 'val']}\n",
    "\n",
    "    \n",
    "    model_ft = models.resnet101(pretrained=True)\n",
    "    num_ftrs = model_ft.fc.in_features\n",
    "    model_ft.fc = nn.Linear(num_ftrs, class_names)\n",
    "    \n",
    "    model_ft = model_ft.to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.0005, momentum=0.9)\n",
    "    exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=6, gamma=0.1)\n",
    "    writer = SummaryWriter('./logs/densenet161_kfold_'+str(i))\n",
    "\n",
    "    model_ft, best_acc = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                                     dataloaders, writer, i, num_epochs=20)\n",
    "    \n",
    "    accuracies.append(best_acc.item())\n",
    "    print(\"\\n\\n\\n------------------------------------\\n Accuracies \", accuracies)\n",
    "    print(\"\\n\\n\")\n",
    "    \n",
    "torch.save(model_ft.state_dict(), 'saved/resnet_101.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'agricultural': 0, 'airplane': 1, 'baseballdiamond': 2, 'beach': 3, 'buildings': 4, 'chaparral': 5, 'denseresidential': 6, 'forest': 7, 'freeway': 8, 'golfcourse': 9, 'harbor': 10, 'intersection': 11, 'mediumresidential': 12, 'mobilehomepark': 13, 'overpass': 14, 'parkinglot': 15, 'river': 16, 'runway': 17, 'sparseresidential': 18, 'storagetanks': 19, 'tenniscourt': 20}\n",
      "{'agricultural': 0, 'airplane': 1, 'baseballdiamond': 2, 'beach': 3, 'buildings': 4, 'chaparral': 5, 'denseresidential': 6, 'forest': 7, 'freeway': 8, 'golfcourse': 9, 'harbor': 10, 'intersection': 11, 'mediumresidential': 12, 'mobilehomepark': 13, 'overpass': 14, 'parkinglot': 15, 'river': 16, 'runway': 17, 'sparseresidential': 18, 'storagetanks': 19, 'tenniscourt': 20}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                          | 0/210 [00:00<?, ?it/s]\n",
      "  1%|█▏                                                                                | 3/210 [00:00<00:09, 21.79it/s]\n",
      "  3%|██▎                                                                               | 6/210 [00:00<00:08, 22.70it/s]\n",
      "  4%|███▌                                                                              | 9/210 [00:00<00:08, 23.44it/s]\n",
      "  6%|████▋                                                                            | 12/210 [00:00<00:08, 23.59it/s]\n",
      "  7%|█████▊                                                                           | 15/210 [00:00<00:08, 23.80it/s]\n",
      "  9%|██████▉                                                                          | 18/210 [00:00<00:07, 24.00it/s]\n",
      " 10%|████████                                                                         | 21/210 [00:00<00:07, 23.98it/s]\n",
      " 11%|█████████▎                                                                       | 24/210 [00:01<00:07, 23.62it/s]\n",
      " 13%|██████████▍                                                                      | 27/210 [00:01<00:07, 23.83it/s]\n",
      " 14%|███████████▌                                                                     | 30/210 [00:01<00:07, 23.50it/s]\n",
      " 16%|████████████▋                                                                    | 33/210 [00:01<00:07, 23.12it/s]\n",
      " 17%|█████████████▉                                                                   | 36/210 [00:01<00:07, 23.18it/s]\n",
      " 19%|███████████████                                                                  | 39/210 [00:01<00:07, 23.29it/s]\n",
      " 20%|████████████████▏                                                                | 42/210 [00:01<00:07, 23.40it/s]\n",
      " 21%|█████████████████▎                                                               | 45/210 [00:01<00:07, 23.43it/s]\n",
      " 23%|██████████████████▌                                                              | 48/210 [00:02<00:06, 23.41it/s]\n",
      " 24%|███████████████████▋                                                             | 51/210 [00:02<00:06, 23.51it/s]\n",
      " 26%|████████████████████▊                                                            | 54/210 [00:02<00:06, 23.57it/s]\n",
      " 27%|█████████████████████▉                                                           | 57/210 [00:02<00:06, 23.63it/s]\n",
      " 29%|███████████████████████▏                                                         | 60/210 [00:02<00:06, 23.69it/s]\n",
      " 30%|████████████████████████▎                                                        | 63/210 [00:02<00:06, 23.76it/s]\n",
      " 31%|█████████████████████████▍                                                       | 66/210 [00:02<00:06, 23.77it/s]\n",
      " 33%|██████████████████████████▌                                                      | 69/210 [00:02<00:05, 23.80it/s]\n",
      " 34%|███████████████████████████▊                                                     | 72/210 [00:03<00:05, 23.87it/s]\n",
      " 36%|████████████████████████████▉                                                    | 75/210 [00:03<00:05, 23.93it/s]\n",
      " 37%|██████████████████████████████                                                   | 78/210 [00:03<00:05, 23.93it/s]\n",
      " 39%|███████████████████████████████▏                                                 | 81/210 [00:03<00:05, 23.99it/s]\n",
      " 40%|████████████████████████████████▍                                                | 84/210 [00:03<00:05, 24.03it/s]\n",
      " 41%|█████████████████████████████████▌                                               | 87/210 [00:03<00:05, 24.08it/s]\n",
      " 43%|██████████████████████████████████▋                                              | 90/210 [00:03<00:04, 24.12it/s]\n",
      " 44%|███████████████████████████████████▊                                             | 93/210 [00:03<00:04, 24.17it/s]\n",
      " 46%|█████████████████████████████████████                                            | 96/210 [00:03<00:04, 24.22it/s]\n",
      " 47%|██████████████████████████████████████▏                                          | 99/210 [00:04<00:04, 24.21it/s]\n",
      " 49%|██████████████████████████████████████▊                                         | 102/210 [00:04<00:04, 24.25it/s]\n",
      " 50%|████████████████████████████████████████                                        | 105/210 [00:04<00:04, 24.21it/s]\n",
      " 51%|█████████████████████████████████████████▏                                      | 108/210 [00:04<00:04, 24.24it/s]\n",
      " 53%|██████████████████████████████████████████▎                                     | 111/210 [00:04<00:04, 24.21it/s]\n",
      " 54%|███████████████████████████████████████████▍                                    | 114/210 [00:04<00:03, 24.16it/s]\n",
      " 56%|████████████████████████████████████████████▌                                   | 117/210 [00:04<00:03, 24.19it/s]\n",
      " 57%|█████████████████████████████████████████████▋                                  | 120/210 [00:04<00:03, 24.19it/s]\n",
      " 59%|██████████████████████████████████████████████▊                                 | 123/210 [00:05<00:03, 24.21it/s]\n",
      " 60%|████████████████████████████████████████████████                                | 126/210 [00:05<00:03, 24.23it/s]\n",
      " 61%|█████████████████████████████████████████████████▏                              | 129/210 [00:05<00:03, 24.23it/s]\n",
      " 63%|██████████████████████████████████████████████████▎                             | 132/210 [00:05<00:03, 24.25it/s]\n",
      " 64%|███████████████████████████████████████████████████▍                            | 135/210 [00:05<00:03, 24.25it/s]\n",
      " 66%|████████████████████████████████████████████████████▌                           | 138/210 [00:05<00:02, 24.27it/s]\n",
      " 67%|█████████████████████████████████████████████████████▋                          | 141/210 [00:05<00:02, 24.28it/s]\n",
      " 69%|██████████████████████████████████████████████████████▊                         | 144/210 [00:05<00:02, 24.28it/s]\n",
      " 70%|████████████████████████████████████████████████████████                        | 147/210 [00:06<00:02, 24.29it/s]\n",
      " 71%|█████████████████████████████████████████████████████████▏                      | 150/210 [00:06<00:02, 24.30it/s]\n",
      " 73%|██████████████████████████████████████████████████████████▎                     | 153/210 [00:06<00:02, 24.28it/s]\n",
      " 74%|███████████████████████████████████████████████████████████▍                    | 156/210 [00:06<00:02, 24.22it/s]\n",
      " 76%|████████████████████████████████████████████████████████████▌                   | 159/210 [00:06<00:02, 24.22it/s]\n",
      " 77%|█████████████████████████████████████████████████████████████▋                  | 162/210 [00:06<00:01, 24.15it/s]\n",
      " 79%|██████████████████████████████████████████████████████████████▊                 | 165/210 [00:06<00:01, 24.15it/s]\n",
      " 80%|████████████████████████████████████████████████████████████████                | 168/210 [00:06<00:01, 24.17it/s]\n",
      " 81%|█████████████████████████████████████████████████████████████████▏              | 171/210 [00:07<00:01, 24.11it/s]\n",
      " 83%|██████████████████████████████████████████████████████████████████▎             | 174/210 [00:07<00:01, 24.13it/s]\n",
      " 84%|███████████████████████████████████████████████████████████████████▍            | 177/210 [00:07<00:01, 24.11it/s]\n",
      " 86%|████████████████████████████████████████████████████████████████████▌           | 180/210 [00:07<00:01, 24.07it/s]\n",
      " 87%|█████████████████████████████████████████████████████████████████████▋          | 183/210 [00:07<00:01, 24.08it/s]\n",
      " 89%|██████████████████████████████████████████████████████████████████████▊         | 186/210 [00:07<00:00, 24.06it/s]\n",
      " 90%|████████████████████████████████████████████████████████████████████████        | 189/210 [00:07<00:00, 24.01it/s]\n",
      " 91%|█████████████████████████████████████████████████████████████████████████▏      | 192/210 [00:08<00:00, 23.98it/s]\n",
      " 93%|██████████████████████████████████████████████████████████████████████████▎     | 195/210 [00:08<00:00, 23.92it/s]\n",
      " 94%|███████████████████████████████████████████████████████████████████████████▍    | 198/210 [00:08<00:00, 23.94it/s]\n",
      " 96%|████████████████████████████████████████████████████████████████████████████▌   | 201/210 [00:08<00:00, 23.95it/s]\n",
      " 97%|█████████████████████████████████████████████████████████████████████████████▋  | 204/210 [00:08<00:00, 23.96it/s]\n",
      " 99%|██████████████████████████████████████████████████████████████████████████████▊ | 207/210 [00:08<00:00, 23.96it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 210/210 [00:08<00:00, 23.95it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[10, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 14, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 11, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 11, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 10, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 11, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 5, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 17, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 8, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 12, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 12]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = model_ft\n",
    "model.eval()\n",
    "result = [[0 for _ in range(21)] for _ in range(21)]\n",
    "\n",
    "dataloaders = {x: torch.utils.data.DataLoader(CustomDataset(transforms_=data_transforms[x], idx=idx[x]), batch_size=1,\n",
    "                                             shuffle=True)\n",
    "              for x in ['train', 'val']}\n",
    "\n",
    "for inputs, labels in tqdm(dataloaders['val']):\n",
    "    inputs = inputs.to(device)\n",
    "    labels = labels.to(device)\n",
    "\n",
    "\n",
    "    outputs = model_ft(inputs)\n",
    "    _, preds = torch.max(outputs, 1)\n",
    "    \n",
    "    row = preds.data[0].cpu().numpy()\n",
    "    col = labels.data[0].cpu().numpy() \n",
    "    result[row][col]+=1\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Row Sum: \n",
      " [10  9 14 10 13 11  3 13 10  4 10  5  7 12 14 17  6  8  9 13 12]\n",
      "\n",
      "Col Sum: \n",
      " [10  9 14 13 13 11  5 11  9  6 10 15  3 11  5 17  7  8  9 12 12]\n",
      "\n",
      "Precision\n",
      " [1.         1.         1.         0.9        1.         1.\n",
      " 1.         0.84615385 0.9        1.         1.         1.\n",
      " 0.42857143 0.91666667 0.35714286 1.         0.83333333 1.\n",
      " 1.         0.92307692 1.        ]\n",
      "\n",
      "Recall\n",
      " [1.         1.         1.         0.69230769 1.         1.\n",
      " 0.6        1.         1.         0.66666667 1.         0.33333333\n",
      " 1.         1.         1.         1.         0.71428571 1.\n",
      " 1.         1.         1.        ]\n",
      "\n",
      "Model average prcision:  0.909759288330717\n",
      "Model average recall:  0.9050758765044478\n",
      "Model accuracy:  0.9047619047619048\n"
     ]
    }
   ],
   "source": [
    "precision = np.zeros(21)\n",
    "recall = np.zeros(21)\n",
    "\n",
    "npr = np.array(result)\n",
    "row_sum = npr.sum(axis=1)\n",
    "print(\"\\nRow Sum: \\n\", row_sum)\n",
    "col_sum = npr.sum(axis=0)\n",
    "print(\"\\nCol Sum: \\n\", col_sum)\n",
    "total_correct = 0\n",
    "\n",
    "for i in range(21):\n",
    "    precision[i] = result[i][i] / row_sum[i]\n",
    "    recall[i] = result[i][i] / col_sum[i]\n",
    "    total_correct += result[i][i]\n",
    "\n",
    "print(\"\\nPrecision\\n\", precision)\n",
    "print(\"\\nRecall\\n\", recall)\n",
    "\n",
    "\n",
    "print()\n",
    "print(\"Model average prcision: \", np.mean(precision))\n",
    "print(\"Model average recall: \", np.mean(recall))\n",
    "print(\"Model accuracy: \", total_correct/210)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resnet 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "index = list(np.random.permutation(2100))\n",
    "\n",
    "for i in range(1):\n",
    "    idx = {'val': index[210*i:210*(i+1)], 'train': index[:i*210]+index[((i+1)*210) -1:]}\n",
    "\n",
    "    dataloaders = {x: torch.utils.data.DataLoader(CustomDataset(transforms_=data_transforms[x], idx=idx[x]), batch_size=8,\n",
    "                                             shuffle=True)\n",
    "              for x in ['train', 'val']}\n",
    "\n",
    "    \n",
    "    model_ft = models.resnet50(pretrained=True)\n",
    "    num_ftrs = model_ft.fc.in_features\n",
    "    model_ft.fc = nn.Linear(num_ftrs, class_names)\n",
    "    \n",
    "    model_ft = model_ft.to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.0005, momentum=0.9)\n",
    "    exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=6, gamma=0.1)\n",
    "    writer = SummaryWriter('./logs/densenet161_kfold_'+str(i))\n",
    "\n",
    "    model_ft, best_acc = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                                     dataloaders, writer, i, num_epochs=20)\n",
    "    \n",
    "    accuracies.append(best_acc.item())\n",
    "    print(\"\\n\\n\\n------------------------------------\\n Accuracies \", accuracies)\n",
    "    print(\"\\n\\n\")\n",
    "    \n",
    "torch.save(model_ft.state_dict(), 'saved/resnet_50.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'agricultural': 0, 'airplane': 1, 'baseballdiamond': 2, 'beach': 3, 'buildings': 4, 'chaparral': 5, 'denseresidential': 6, 'forest': 7, 'freeway': 8, 'golfcourse': 9, 'harbor': 10, 'intersection': 11, 'mediumresidential': 12, 'mobilehomepark': 13, 'overpass': 14, 'parkinglot': 15, 'river': 16, 'runway': 17, 'sparseresidential': 18, 'storagetanks': 19, 'tenniscourt': 20}\n",
      "{'agricultural': 0, 'airplane': 1, 'baseballdiamond': 2, 'beach': 3, 'buildings': 4, 'chaparral': 5, 'denseresidential': 6, 'forest': 7, 'freeway': 8, 'golfcourse': 9, 'harbor': 10, 'intersection': 11, 'mediumresidential': 12, 'mobilehomepark': 13, 'overpass': 14, 'parkinglot': 15, 'river': 16, 'runway': 17, 'sparseresidential': 18, 'storagetanks': 19, 'tenniscourt': 20}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                          | 0/210 [00:00<?, ?it/s]\n",
      "  1%|█▏                                                                                | 3/210 [00:00<00:09, 21.49it/s]\n",
      "  3%|██▎                                                                               | 6/210 [00:00<00:09, 21.49it/s]\n",
      "  4%|███▌                                                                              | 9/210 [00:00<00:08, 22.62it/s]\n",
      "  6%|████▋                                                                            | 12/210 [00:00<00:08, 23.01it/s]\n",
      "  7%|█████▊                                                                           | 15/210 [00:00<00:08, 23.43it/s]\n",
      "  9%|██████▉                                                                          | 18/210 [00:00<00:08, 23.53it/s]\n",
      " 10%|████████                                                                         | 21/210 [00:00<00:07, 23.63it/s]\n",
      " 11%|█████████▎                                                                       | 24/210 [00:01<00:07, 23.83it/s]\n",
      " 13%|██████████▍                                                                      | 27/210 [00:01<00:07, 24.00it/s]\n",
      " 14%|███████████▌                                                                     | 30/210 [00:01<00:07, 24.08it/s]\n",
      " 16%|████████████▋                                                                    | 33/210 [00:01<00:07, 24.11it/s]\n",
      " 17%|█████████████▉                                                                   | 36/210 [00:01<00:07, 24.08it/s]\n",
      " 19%|███████████████                                                                  | 39/210 [00:01<00:07, 24.18it/s]\n",
      " 20%|████████████████▏                                                                | 42/210 [00:01<00:06, 24.24it/s]\n",
      " 21%|█████████████████▎                                                               | 45/210 [00:01<00:06, 24.14it/s]\n",
      " 23%|██████████████████▌                                                              | 48/210 [00:02<00:06, 23.85it/s]\n",
      " 24%|███████████████████▋                                                             | 51/210 [00:02<00:06, 23.77it/s]\n",
      " 26%|████████████████████▊                                                            | 54/210 [00:02<00:06, 23.83it/s]\n",
      " 27%|█████████████████████▉                                                           | 57/210 [00:02<00:06, 23.90it/s]\n",
      " 29%|███████████████████████▏                                                         | 60/210 [00:02<00:06, 23.95it/s]\n",
      " 30%|████████████████████████▎                                                        | 63/210 [00:02<00:06, 23.96it/s]\n",
      " 31%|█████████████████████████▍                                                       | 66/210 [00:02<00:06, 23.95it/s]\n",
      " 33%|██████████████████████████▌                                                      | 69/210 [00:02<00:05, 23.97it/s]\n",
      " 34%|███████████████████████████▊                                                     | 72/210 [00:03<00:05, 23.95it/s]\n",
      " 36%|████████████████████████████▉                                                    | 75/210 [00:03<00:05, 24.00it/s]\n",
      " 37%|██████████████████████████████                                                   | 78/210 [00:03<00:05, 24.04it/s]\n",
      " 39%|███████████████████████████████▏                                                 | 81/210 [00:03<00:05, 24.06it/s]\n",
      " 40%|████████████████████████████████▍                                                | 84/210 [00:03<00:05, 24.05it/s]\n",
      " 41%|█████████████████████████████████▌                                               | 87/210 [00:03<00:05, 24.02it/s]\n",
      " 43%|██████████████████████████████████▋                                              | 90/210 [00:03<00:05, 23.82it/s]\n",
      " 44%|███████████████████████████████████▊                                             | 93/210 [00:03<00:04, 23.81it/s]\n",
      " 46%|█████████████████████████████████████                                            | 96/210 [00:04<00:04, 23.75it/s]\n",
      " 47%|██████████████████████████████████████▏                                          | 99/210 [00:04<00:04, 23.79it/s]\n",
      " 49%|██████████████████████████████████████▊                                         | 102/210 [00:04<00:04, 23.84it/s]\n",
      " 50%|████████████████████████████████████████                                        | 105/210 [00:04<00:04, 23.80it/s]\n",
      " 51%|█████████████████████████████████████████▏                                      | 108/210 [00:04<00:04, 23.73it/s]\n",
      " 53%|██████████████████████████████████████████▎                                     | 111/210 [00:04<00:04, 23.68it/s]\n",
      " 54%|███████████████████████████████████████████▍                                    | 114/210 [00:04<00:04, 23.69it/s]\n",
      " 56%|████████████████████████████████████████████▌                                   | 117/210 [00:04<00:03, 23.72it/s]\n",
      " 57%|█████████████████████████████████████████████▋                                  | 120/210 [00:05<00:03, 23.67it/s]\n",
      " 59%|██████████████████████████████████████████████▊                                 | 123/210 [00:05<00:03, 23.65it/s]\n",
      " 60%|████████████████████████████████████████████████                                | 126/210 [00:05<00:03, 23.67it/s]\n",
      " 61%|█████████████████████████████████████████████████▏                              | 129/210 [00:05<00:03, 23.67it/s]\n",
      " 63%|██████████████████████████████████████████████████▎                             | 132/210 [00:05<00:03, 23.67it/s]\n",
      " 64%|███████████████████████████████████████████████████▍                            | 135/210 [00:05<00:03, 23.60it/s]\n",
      " 66%|████████████████████████████████████████████████████▌                           | 138/210 [00:05<00:03, 23.57it/s]\n",
      " 67%|█████████████████████████████████████████████████████▋                          | 141/210 [00:05<00:02, 23.58it/s]\n",
      " 69%|██████████████████████████████████████████████████████▊                         | 144/210 [00:06<00:02, 23.61it/s]\n",
      " 70%|████████████████████████████████████████████████████████                        | 147/210 [00:06<00:02, 23.61it/s]\n",
      " 71%|█████████████████████████████████████████████████████████▏                      | 150/210 [00:06<00:02, 23.64it/s]\n",
      " 73%|██████████████████████████████████████████████████████████▎                     | 153/210 [00:06<00:02, 23.66it/s]\n",
      " 74%|███████████████████████████████████████████████████████████▍                    | 156/210 [00:06<00:02, 23.66it/s]\n",
      " 76%|████████████████████████████████████████████████████████████▌                   | 159/210 [00:06<00:02, 23.68it/s]\n",
      " 77%|█████████████████████████████████████████████████████████████▋                  | 162/210 [00:06<00:02, 23.62it/s]\n",
      " 79%|██████████████████████████████████████████████████████████████▊                 | 165/210 [00:06<00:01, 23.62it/s]\n",
      " 80%|████████████████████████████████████████████████████████████████                | 168/210 [00:07<00:01, 23.64it/s]\n",
      " 81%|█████████████████████████████████████████████████████████████████▏              | 171/210 [00:07<00:01, 23.64it/s]\n",
      " 83%|██████████████████████████████████████████████████████████████████▎             | 174/210 [00:07<00:01, 23.58it/s]\n",
      " 84%|███████████████████████████████████████████████████████████████████▍            | 177/210 [00:07<00:01, 23.56it/s]\n",
      " 86%|████████████████████████████████████████████████████████████████████▌           | 180/210 [00:07<00:01, 23.57it/s]\n",
      " 87%|█████████████████████████████████████████████████████████████████████▋          | 183/210 [00:07<00:01, 23.57it/s]\n",
      " 89%|██████████████████████████████████████████████████████████████████████▊         | 186/210 [00:07<00:01, 23.58it/s]\n",
      " 90%|████████████████████████████████████████████████████████████████████████        | 189/210 [00:08<00:00, 23.59it/s]\n",
      " 91%|█████████████████████████████████████████████████████████████████████████▏      | 192/210 [00:08<00:00, 23.61it/s]\n",
      " 93%|██████████████████████████████████████████████████████████████████████████▎     | 195/210 [00:08<00:00, 23.63it/s]\n",
      " 94%|███████████████████████████████████████████████████████████████████████████▍    | 198/210 [00:08<00:00, 23.63it/s]\n",
      " 96%|████████████████████████████████████████████████████████████████████████████▌   | 201/210 [00:08<00:00, 23.65it/s]\n",
      " 97%|█████████████████████████████████████████████████████████████████████████████▋  | 204/210 [00:08<00:00, 23.64it/s]\n",
      " 99%|██████████████████████████████████████████████████████████████████████████████▊ | 207/210 [00:08<00:00, 23.62it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 210/210 [00:08<00:00, 23.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Row Sum: \n",
      " [10  9 14 10 13 11  3 13 10  4 10  5  7 12 14 17  6  8  9 13 12]\n",
      "\n",
      "Col Sum: \n",
      " [10  9 14 13 13 11  5 11  9  6 10 15  3 11  5 17  7  8  9 12 12]\n",
      "\n",
      "Precision\n",
      " [1.         1.         1.         0.9        1.         1.\n",
      " 1.         0.84615385 0.9        1.         1.         1.\n",
      " 0.42857143 0.91666667 0.35714286 1.         0.83333333 1.\n",
      " 1.         0.92307692 1.        ]\n",
      "\n",
      "Recall\n",
      " [1.         1.         1.         0.69230769 1.         1.\n",
      " 0.6        1.         1.         0.66666667 1.         0.33333333\n",
      " 1.         1.         1.         1.         0.71428571 1.\n",
      " 1.         1.         1.        ]\n",
      "\n",
      "Model average prcision:  0.909759288330717\n",
      "Model average recall:  0.9050758765044478\n",
      "Model accuracy:  0.9047619047619048\n"
     ]
    }
   ],
   "source": [
    "model = model_ft\n",
    "model.eval()\n",
    "result = [[0 for _ in range(21)] for _ in range(21)]\n",
    "\n",
    "dataloaders = {x: torch.utils.data.DataLoader(CustomDataset(transforms_=data_transforms[x], idx=idx[x]), batch_size=1,\n",
    "                                             shuffle=True)\n",
    "              for x in ['train', 'val']}\n",
    "\n",
    "for inputs, labels in tqdm(dataloaders['val']):\n",
    "    inputs = inputs.to(device)\n",
    "    labels = labels.to(device)\n",
    "\n",
    "\n",
    "    outputs = model_ft(inputs)\n",
    "    _, preds = torch.max(outputs, 1)\n",
    "    \n",
    "    row = preds.data[0].cpu().numpy()\n",
    "    col = labels.data[0].cpu().numpy() \n",
    "    result[row][col]+=1\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = np.zeros(21)\n",
    "recall = np.zeros(21)\n",
    "\n",
    "npr = np.array(result)\n",
    "row_sum = npr.sum(axis=1)\n",
    "print(\"\\nRow Sum: \\n\", row_sum)\n",
    "col_sum = npr.sum(axis=0)\n",
    "print(\"\\nCol Sum: \\n\", col_sum)\n",
    "total_correct = 0\n",
    "\n",
    "for i in range(21):\n",
    "    precision[i] = result[i][i] / row_sum[i]\n",
    "    recall[i] = result[i][i] / col_sum[i]\n",
    "    total_correct += result[i][i]\n",
    "\n",
    "print(\"\\nPrecision\\n\", precision)\n",
    "print(\"\\nRecall\\n\", recall)\n",
    "\n",
    "\n",
    "print()\n",
    "print(\"Model average prcision: \", np.mean(precision))\n",
    "print(\"Model average recall: \", np.mean(recall))\n",
    "print(\"Model accuracy: \", total_correct/210)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resnet 34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "index = list(np.random.permutation(2100))\n",
    "\n",
    "for i in range(1):\n",
    "    idx = {'val': index[210*i:210*(i+1)], 'train': index[:i*210]+index[((i+1)*210) -1:]}\n",
    "\n",
    "    dataloaders = {x: torch.utils.data.DataLoader(CustomDataset(transforms_=data_transforms[x], idx=idx[x]), batch_size=8,\n",
    "                                             shuffle=True)\n",
    "              for x in ['train', 'val']}\n",
    "\n",
    "    \n",
    "    model_ft = models.resnet34(pretrained=True)\n",
    "    num_ftrs = model_ft.fc.in_features\n",
    "    model_ft.fc = nn.Linear(num_ftrs, class_names)\n",
    "    \n",
    "    model_ft = model_ft.to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.0005, momentum=0.9)\n",
    "    exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=6, gamma=0.1)\n",
    "    writer = SummaryWriter('./logs/densenet161_kfold_'+str(i))\n",
    "\n",
    "    model_ft, best_acc = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                                     dataloaders, writer, i, num_epochs=20)\n",
    "    \n",
    "    accuracies.append(best_acc.item())\n",
    "    print(\"\\n\\n\\n------------------------------------\\n Accuracies \", accuracies)\n",
    "    print(\"\\n\\n\")\n",
    "    \n",
    "torch.save(model_ft.state_dict(), 'saved/resnet_34.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_ft\n",
    "model.eval()\n",
    "result = [[0 for _ in range(21)] for _ in range(21)]\n",
    "\n",
    "dataloaders = {x: torch.utils.data.DataLoader(CustomDataset(transforms_=data_transforms[x], idx=idx[x]), batch_size=1,\n",
    "                                             shuffle=True)\n",
    "              for x in ['train', 'val']}\n",
    "\n",
    "for inputs, labels in tqdm(dataloaders['val']):\n",
    "    inputs = inputs.to(device)\n",
    "    labels = labels.to(device)\n",
    "\n",
    "\n",
    "    outputs = model_ft(inputs)\n",
    "    _, preds = torch.max(outputs, 1)\n",
    "    \n",
    "    row = preds.data[0].cpu().numpy()\n",
    "    col = labels.data[0].cpu().numpy() \n",
    "    result[row][col]+=1\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = np.zeros(21)\n",
    "recall = np.zeros(21)\n",
    "\n",
    "npr = np.array(result)\n",
    "row_sum = npr.sum(axis=1)\n",
    "print(\"\\nRow Sum: \\n\", row_sum)\n",
    "col_sum = npr.sum(axis=0)\n",
    "print(\"\\nCol Sum: \\n\", col_sum)\n",
    "total_correct = 0\n",
    "\n",
    "for i in range(21):\n",
    "    precision[i] = result[i][i] / row_sum[i]\n",
    "    recall[i] = result[i][i] / col_sum[i]\n",
    "    total_correct += result[i][i]\n",
    "\n",
    "print(\"\\nPrecision\\n\", precision)\n",
    "print(\"\\nRecall\\n\", recall)\n",
    "\n",
    "\n",
    "print()\n",
    "print(\"Model average prcision: \", np.mean(precision))\n",
    "print(\"Model average recall: \", np.mean(recall))\n",
    "print(\"Model accuracy: \", total_correct/210)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resnet 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "index = list(np.random.permutation(2100))\n",
    "\n",
    "for i in range(1):\n",
    "    idx = {'val': index[210*i:210*(i+1)], 'train': index[:i*210]+index[((i+1)*210) -1:]}\n",
    "\n",
    "    dataloaders = {x: torch.utils.data.DataLoader(CustomDataset(transforms_=data_transforms[x], idx=idx[x]), batch_size=8,\n",
    "                                             shuffle=True)\n",
    "              for x in ['train', 'val']}\n",
    "\n",
    "    \n",
    "    model_ft = models.resnet18(pretrained=True)\n",
    "    num_ftrs = model_ft.fc.in_features\n",
    "    model_ft.fc = nn.Linear(num_ftrs, class_names)\n",
    "    \n",
    "    model_ft = model_ft.to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.0005, momentum=0.9)\n",
    "    exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=6, gamma=0.1)\n",
    "    writer = SummaryWriter('./logs/densenet161_kfold_'+str(i))\n",
    "\n",
    "    model_ft, best_acc = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                                     dataloaders, writer, i, num_epochs=20)\n",
    "    \n",
    "    accuracies.append(best_acc.item())\n",
    "    print(\"\\n\\n\\n------------------------------------\\n Accuracies \", accuracies)\n",
    "    print(\"\\n\\n\")\n",
    "    \n",
    "torch.save(model_ft.state_dict(), 'saved/resnet_18.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_ft\n",
    "model.eval()\n",
    "result = [[0 for _ in range(21)] for _ in range(21)]\n",
    "\n",
    "dataloaders = {x: torch.utils.data.DataLoader(CustomDataset(transforms_=data_transforms[x], idx=idx[x]), batch_size=1,\n",
    "                                             shuffle=True)\n",
    "              for x in ['train', 'val']}\n",
    "\n",
    "for inputs, labels in tqdm(dataloaders['val']):\n",
    "    inputs = inputs.to(device)\n",
    "    labels = labels.to(device)\n",
    "\n",
    "\n",
    "    outputs = model_ft(inputs)\n",
    "    _, preds = torch.max(outputs, 1)\n",
    "    \n",
    "    row = preds.data[0].cpu().numpy()\n",
    "    col = labels.data[0].cpu().numpy() \n",
    "    result[row][col]+=1\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = np.zeros(21)\n",
    "recall = np.zeros(21)\n",
    "\n",
    "npr = np.array(result)\n",
    "row_sum = npr.sum(axis=1)\n",
    "print(\"\\nRow Sum: \\n\", row_sum)\n",
    "col_sum = npr.sum(axis=0)\n",
    "print(\"\\nCol Sum: \\n\", col_sum)\n",
    "total_correct = 0\n",
    "\n",
    "for i in range(21):\n",
    "    precision[i] = result[i][i] / row_sum[i]\n",
    "    recall[i] = result[i][i] / col_sum[i]\n",
    "    total_correct += result[i][i]\n",
    "\n",
    "print(\"\\nPrecision\\n\", precision)\n",
    "print(\"\\nRecall\\n\", recall)\n",
    "\n",
    "\n",
    "print()\n",
    "print(\"Model average prcision: \", np.mean(precision))\n",
    "print(\"Model average recall: \", np.mean(recall))\n",
    "print(\"Model accuracy: \", total_correct/210)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
